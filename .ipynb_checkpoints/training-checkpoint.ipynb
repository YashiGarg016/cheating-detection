{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff0d811e-8148-4035-9123-eefe80e5926d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mediapipe'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmediapipe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YOLO\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'mediapipe'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "# -------------------- Initialize models --------------------\n",
    "PHONE_CLASSES = [\"cell phone\", \"mobile phone\"]\n",
    "phone_model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks=True, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "POSE_LANDMARKS = [1, 33, 263, 61, 291, 199]\n",
    "LEFT_EYE = [33, 133, 159, 145]\n",
    "LEFT_IRIS = [468, 469, 470, 471]\n",
    "RIGHT_EYE = [362, 263, 386, 374]\n",
    "RIGHT_IRIS = [473, 474, 475, 476]\n",
    "\n",
    "# -------------------- Smoothers --------------------\n",
    "class TwoDimSmoother:\n",
    "    def __init__(self, alpha=0.3):\n",
    "        self.alpha = alpha\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "    def apply(self, newx, newy):\n",
    "        if self.x is None:\n",
    "            self.x, self.y = newx, newy\n",
    "        else:\n",
    "            self.x = (1 - self.alpha) * self.x + self.alpha * newx\n",
    "            self.y = (1 - self.alpha) * self.y + self.alpha * newy\n",
    "        return int(self.x), int(self.y)\n",
    "\n",
    "class HeadPoseSmoother:\n",
    "    def __init__(self, alpha=0.2):\n",
    "        self.alpha = alpha\n",
    "        self.pitch = None\n",
    "        self.yaw = None\n",
    "        self.roll = None\n",
    "    def apply(self, pitch, yaw, roll):\n",
    "        if self.pitch is None:\n",
    "            self.pitch, self.yaw, self.roll = pitch, yaw, roll\n",
    "        else:\n",
    "            self.pitch = (1 - self.alpha) * self.pitch + self.alpha * pitch\n",
    "            self.yaw   = (1 - self.alpha) * self.yaw   + self.alpha * yaw\n",
    "            self.roll  = (1 - self.alpha) * self.roll  + self.alpha * roll\n",
    "        return self.pitch, self.yaw, self.roll\n",
    "\n",
    "kalman_left = TwoDimSmoother()\n",
    "kalman_right = TwoDimSmoother()\n",
    "head_smoother = HeadPoseSmoother()\n",
    "\n",
    "# -------------------- Eye direction --------------------\n",
    "def get_eye_direction(landmarks, eye_idx, iris_idx, w, h, smoother):\n",
    "    eye = [(int(landmarks[i].x * w), int(landmarks[i].y * h)) for i in eye_idx]\n",
    "    iris_pts = [(int(landmarks[i].x * w), int(landmarks[i].y * h)) for i in iris_idx]\n",
    "    iris_cx = sum([p[0] for p in iris_pts]) / len(iris_pts)\n",
    "    iris_cy = sum([p[1] for p in iris_pts]) / len(iris_pts)\n",
    "    iris_x, iris_y = smoother.apply(iris_cx, iris_cy)\n",
    "\n",
    "    left, right = min(eye[0][0], eye[1][0]), max(eye[0][0], eye[1][0])\n",
    "    top, bottom = min(eye[2][1], eye[3][1]), max(eye[2][1], eye[3][1])\n",
    "\n",
    "    margin_x = int((right - left) * 0.15)\n",
    "    margin_y = int((bottom - top) * 0.20)\n",
    "\n",
    "    # Determine gaze direction and offsets\n",
    "    if iris_x < left + margin_x:\n",
    "        return \"LEFT\", iris_x - (left + margin_x), iris_y - (top + margin_y)\n",
    "    elif iris_x > right - margin_x:\n",
    "        return \"RIGHT\", iris_x - (left + margin_x), iris_y - (top + margin_y)\n",
    "    elif iris_y < top + margin_y:\n",
    "        return \"UP\", iris_x - (left + margin_x), iris_y - (top + margin_y)\n",
    "    elif iris_y > bottom - margin_y:\n",
    "        return \"DOWN\", iris_x - (left + margin_x), iris_y - (top + margin_y)\n",
    "    else:\n",
    "        return \"CENTER\", iris_x - (left + margin_x), iris_y - (top + margin_y)\n",
    "\n",
    "# -------------------- Head pose --------------------\n",
    "def estimate_head_pose(landmarks, w, h):\n",
    "    image_points = np.array([(landmarks[idx].x * w, landmarks[idx].y * h) for idx in POSE_LANDMARKS], dtype=\"double\")\n",
    "    model_points = np.array([\n",
    "        (0.0, 0.0, 0.0),\n",
    "        (-30.0, 0.0, -30.0),\n",
    "        (30.0, 0.0, -30.0),\n",
    "        (-30.0, 0.0, -90.0),\n",
    "        (30.0, 0.0, -90.0),\n",
    "        (0.0, 40.0, -50.0)\n",
    "    ])\n",
    "    focal_length = w\n",
    "    center = (w / 2, h / 2)\n",
    "    camera_matrix = np.array([[focal_length,0,center[0]],[0,focal_length,center[1]],[0,0,1]])\n",
    "    dist_coeffs = np.zeros((4,1))\n",
    "    success, rotation_vector, _ = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "    return rotation_vector if success else None\n",
    "\n",
    "# -------------------- Collect data --------------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "dir_map = {\"LEFT\":0,\"RIGHT\":1,\"UP\":2,\"DOWN\":3,\"CENTER\":4}\n",
    "\n",
    "columns = [\"left_dir\",\"right_dir\",\"left_dx\",\"left_dy\",\"right_dx\",\"right_dy\",\n",
    "           \"pitch\",\"yaw\",\"roll\",\"phone_detected\",\"eyes_away_duration\",\"label\"]\n",
    "data_rows = []\n",
    "\n",
    "away_start_time = None\n",
    "AWAY_THRESHOLD = 0.8\n",
    "\n",
    "print(\"Press 0 for FOCUSED, 1 for DISTRACTED, ESC to quit and train model.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    frame = cv2.flip(frame,1)\n",
    "    h,w,_ = frame.shape\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    eyes_away = False\n",
    "    phone_detected = 0\n",
    "\n",
    "    # Face and eyes\n",
    "    face_results = face_mesh.process(rgb)\n",
    "    left_dir = right_dir = \"CENTER\"\n",
    "    left_dx = left_dy = right_dx = right_dy = 0\n",
    "    pitch = yaw = roll = 0\n",
    "    eyes_away_duration = 0\n",
    "\n",
    "    if face_results.multi_face_landmarks:\n",
    "        landmarks = face_results.multi_face_landmarks[0].landmark\n",
    "        left_dir, left_dx, left_dy = get_eye_direction(landmarks, LEFT_EYE, LEFT_IRIS, w, h, kalman_left)\n",
    "        right_dir, right_dx, right_dy = get_eye_direction(landmarks, RIGHT_EYE, RIGHT_IRIS, w, h, kalman_right)\n",
    "        rot_vec = estimate_head_pose(landmarks, w, h)\n",
    "        if rot_vec is not None:\n",
    "            pitch, yaw, roll = head_smoother.apply(*rot_vec.ravel())\n",
    "        if left_dir!=\"CENTER\" or right_dir!=\"CENTER\":\n",
    "            eyes_away = True\n",
    "\n",
    "    # Phone detection\n",
    "    results = phone_model(frame, verbose=False)\n",
    "    for box in results[0].boxes:\n",
    "        cls = int(box.cls[0])\n",
    "        label = phone_model.names[cls]\n",
    "        conf = float(box.conf[0])\n",
    "        if label in PHONE_CLASSES and conf>0.5:\n",
    "            phone_detected = 1\n",
    "\n",
    "    # Eye-away timer\n",
    "    current_time = time.time()\n",
    "    if eyes_away:\n",
    "        if away_start_time is None: away_start_time=current_time\n",
    "        eyes_away_duration = current_time - away_start_time\n",
    "    else:\n",
    "        away_start_time=None\n",
    "        eyes_away_duration=0\n",
    "\n",
    "    # Display frame\n",
    "    cv2.putText(frame,\"Press 0:FOCUSED 1:DISTRACTED\",(10,30),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,255,255),2)\n",
    "    cv2.imshow(\"Data Collection\", frame)\n",
    "\n",
    "    # Wait for key\n",
    "    key = cv2.waitKey(1)\n",
    "    if key==27: break  # ESC to quit\n",
    "    label = None\n",
    "    if key==ord(\"0\"): label=0\n",
    "    elif key==ord(\"1\"): label=1\n",
    "    if label is not None:\n",
    "        row = [dir_map[left_dir], dir_map[right_dir], left_dx, left_dy, right_dx, right_dy,\n",
    "               pitch, yaw, roll, phone_detected, eyes_away_duration, label]\n",
    "        data_rows.append(row)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# -------------------- Train model --------------------\n",
    "df = pd.DataFrame(data_rows, columns=columns)\n",
    "X = df.drop(\"label\", axis=1)\n",
    "y = df[\"label\"]\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X, y)\n",
    "\n",
    "joblib.dump(clf, \"gaze_model.pkl\")\n",
    "print(\"Model trained and saved as gaze_model.pkl!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfddddb-4a69-4b80-b696-ab3ef3281ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
